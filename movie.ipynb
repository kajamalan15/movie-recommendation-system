{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "movies = pd.read_csv(r'E:\\3rd Year 1st semi\\IRWA\\Movie_Recomendation_system\\recommendation-system\\DataSet\\movies.csv')\n",
    "ratings = pd.read_csv(r'E:\\3rd Year 1st semi\\IRWA\\Movie_Recomendation_system\\recommendation-system\\DataSet\\ratings.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9125 entries, 0 to 9124\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  9125 non-null   int64 \n",
      " 1   title    9125 non-null   object\n",
      " 2   genres   9125 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 214.0+ KB\n",
      "None\n",
      "\n",
      "Ratings Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100004 entries, 0 to 100003\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100004 non-null  int64  \n",
      " 1   movieId    100004 non-null  int64  \n",
      " 2   rating     100004 non-null  float64\n",
      " 3   timestamp  100004 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data overview\n",
    "print(\"Movies Dataset Info:\")\n",
    "print(movies.info())\n",
    "print(\"\\nRatings Dataset Info:\")\n",
    "print(ratings.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Movies:\n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Ratings:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Movies:\")\n",
    "print(movies.isnull().sum())\n",
    "print(\"\\nMissing Values in Ratings:\")\n",
    "print(ratings.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on movie ID\n",
    "merged_data = pd.merge(ratings, movies, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-item matrix\n",
    "user_item_matrix = merged_data.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "sparse_user_item_matrix = csr_matrix(user_item_matrix)\n",
    "\n",
    "\n",
    "\n",
    "n_components = 10  # Adjust as necessary\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "reduced_matrix = svd.fit_transform(sparse_user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collaborative Filtering (User-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User-based recommendations for User 1: [61, 259, 680, 344, 36]\n"
     ]
    }
   ],
   "source": [
    "# Fit the Nearest Neighbors model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)\n",
    "model_knn.fit(reduced_matrix)\n",
    "\n",
    "# Function to get user-based recommendations\n",
    "def get_user_based_recommendations(user_id, n_recommendations=5):\n",
    "    user_index = user_item_matrix.index.get_loc(user_id)\n",
    "    distances, indices = model_knn.kneighbors(reduced_matrix[user_index].reshape(1, -1), n_neighbors=n_recommendations + 1)\n",
    "    \n",
    "    # Get the recommended movie IDs\n",
    "    recommended_movie_indices = indices.flatten()[1:]\n",
    "    return user_item_matrix.columns[recommended_movie_indices].tolist()\n",
    "\n",
    "# Example usage\n",
    "user_id_example = 1\n",
    "print(\"\\nUser-based recommendations for User 1:\", get_user_based_recommendations(user_id_example, n_recommendations=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Content-based recommendations for 'Toy Story (1995)': ['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story of Terror (2013)', \"We're Back! A Dinosaur's Story (1993)\", 'Balto (1995)']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization for movie titles and genres\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies['title'] + ' ' + movies['genres'].fillna(''))\n",
    "\n",
    "# Compute cosine similarity for content-based filtering\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Function to get content-based recommendations\n",
    "def get_content_based_recommendations(movie_title, n_recommendations=5):\n",
    "    idx = movies[movies['title'] == movie_title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort the movies based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the indices of the top n recommendations\n",
    "    recommended_indices = [i[0] for i in sim_scores[1:n_recommendations + 1]]\n",
    "    return movies['title'].iloc[recommended_indices].tolist()\n",
    "\n",
    "# Example usage\n",
    "movie_title_example = \"Toy Story (1995)\"\n",
    "print(\"\\nContent-based recommendations for 'Toy Story (1995)':\", get_content_based_recommendations(movie_title_example, n_recommendations=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid recommendations for User 1 and 'Toy Story (1995)': ['Toy Story 3 (2010)', 259, 36, 'Toy Story of Terror (2013)', 680]\n"
     ]
    }
   ],
   "source": [
    "# Function to get hybrid recommendations\n",
    "def get_hybrid_recommendations(user_id, movie_title, n_recommendations=5):\n",
    "    user_based_recommendations = get_user_based_recommendations(user_id, n_recommendations)\n",
    "    content_based_recommendations = get_content_based_recommendations(movie_title, n_recommendations)\n",
    "    \n",
    "    # Combine both recommendations\n",
    "    combined_recommendations = list(set(user_based_recommendations) | set(content_based_recommendations))\n",
    "    return combined_recommendations[:n_recommendations]\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nHybrid recommendations for User 1 and 'Toy Story (1995)':\", get_hybrid_recommendations(user_id_example, movie_title_example, n_recommendations=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "RMSE: 0.00\n",
      "MAE: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Create a test set\n",
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Generate predictions using user-based collaborative filtering\n",
    "def predict_rating(user_id, movie_id):\n",
    "    if movie_id in user_item_matrix.columns:\n",
    "        user_index = user_item_matrix.index.get_loc(user_id)\n",
    "        movie_index = user_item_matrix.columns.get_loc(movie_id)\n",
    "        return user_item_matrix.iloc[user_index, movie_index]\n",
    "    else:\n",
    "        return 0  # Or some other default value if the movie was not rated by the user\n",
    "\n",
    "# Create actual and predicted ratings\n",
    "actual_ratings = test_data[['userId', 'movieId', 'rating']]\n",
    "predicted_ratings = actual_ratings.copy()\n",
    "predicted_ratings['predicted_rating'] = predicted_ratings.apply(lambda x: predict_rating(x['userId'], x['movieId']), axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(actual_ratings['rating'].round(), predicted_ratings['predicted_rating'].round(), average='weighted', zero_division=0)\n",
    "recall = recall_score(actual_ratings['rating'].round(), predicted_ratings['predicted_rating'].round(), average='weighted', zero_division=0)\n",
    "f1 = f1_score(actual_ratings['rating'].round(), predicted_ratings['predicted_rating'].round(), average='weighted', zero_division=0)\n",
    "rmse = np.sqrt(mean_squared_error(actual_ratings['rating'], predicted_ratings['predicted_rating']))\n",
    "mae = mean_absolute_error(actual_ratings['rating'], predicted_ratings['predicted_rating'])\n",
    "\n",
    "print(f\"\\nPrecision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
